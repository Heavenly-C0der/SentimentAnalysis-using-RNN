{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b4c08c11",
      "metadata": {
        "id": "b4c08c11"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "import dask.dataframe as dd\n",
        "import kagglehub\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8b5c44c6",
      "metadata": {
        "id": "8b5c44c6"
      },
      "outputs": [],
      "source": [
        "#nltk.download('stopwords')\n",
        "#nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "jLYtQ68U-Lw5",
      "metadata": {
        "id": "jLYtQ68U-Lw5"
      },
      "outputs": [],
      "source": [
        "#!pip install dask[complete]  # Install Dask along with its required dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nZrd2x3L_FnO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZrd2x3L_FnO",
        "outputId": "f1e56830-7f0e-4333-b351-dae0eb4497d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "D:/coding/Notebooks/Projects/data/training.1600000.processed.noemoticon.csv exists!\n",
            "CSV file found: D:/coding/Notebooks/Projects/data/training.1600000.processed.noemoticon.csv\n",
            "Columns in the dataset:\n",
            "['target', 'id', 'date', 'meta', 'user', 'text']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Download latest version\n",
        "dataset_path = kagglehub.dataset_download(\"kazanova/sentiment140\")\n",
        "file_path = \"D:/coding/Notebooks/Projects/data/training.1600000.processed.noemoticon.csv\" #Change this to your path\n",
        "# Find the CSV file within the downloaded directory\n",
        "if os.path.isfile(file_path):\n",
        "    print(f\"{file_path} exists!\")\n",
        "    csv_file_path = file_path\n",
        "else:\n",
        "    print(f\"{file_path} does not exist.\")\n",
        "    for filename in os.listdir(dataset_path):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            csv_file_path = os.path.join(dataset_path, filename)\n",
        "            break  # Stop after finding the first CSV file\n",
        "print(f\"CSV file found: {csv_file_path}\")\n",
        "# Now use the csv_file_path to read the data\n",
        "data = pd.read_csv(csv_file_path, encoding='latin-1', header=None, names=[\"target\", \"id\", \"date\", \"meta\", \"user\", \"text\"])\n",
        "print(\"Columns in the dataset:\")\n",
        "print(data.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "654d50d1",
      "metadata": {
        "id": "654d50d1"
      },
      "outputs": [],
      "source": [
        "data['sentiment'] = data['target']\n",
        "data.drop(columns =[\"id\", \"date\", \"meta\", \"user\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "77835e1c",
      "metadata": {
        "id": "77835e1c"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85da1fa5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85da1fa5",
        "outputId": "e7cb8de4-baf9-4750-81d6-331eb275d174"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = dd.from_pandas(data, npartitions=16)\n",
        "# Compile regex patterns once for speed\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "html_pattern = re.compile(r'<.*?>')  # HTML tags\n",
        "special_pattern = re.compile(r'[^a-z\\s]')  # Keep only a-z and spaces\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# --- Main cleaning function ---\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    text = html_pattern.sub(r'', text)\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    text = special_pattern.sub(r'', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
        "\n",
        "    #tokens = text.split()\n",
        "    #tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Optional lemmatization\n",
        "    #return ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "# --- For batch cleaning ---\n",
        "data['text'] = data['text'].map(clean_text, meta=('x', 'object'))\n",
        "cleaned_data = data.compute()\n",
        "\n",
        "# Now you can work with the cleaned DataFrame (as a Pandas DataFrame)\n",
        "print(cleaned_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af54af0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "cleaned_data.to_csv('data/data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d987bb7b",
      "metadata": {
        "id": "d987bb7b"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data/data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "m3VCRlCrAxcV",
      "metadata": {
        "id": "m3VCRlCrAxcV"
      },
      "outputs": [],
      "source": [
        "data['sentiment'] = data['target'].apply(lambda x: 0 if x == 0 else (1 if x == 2 else 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "HhMYQ70mBH3F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HhMYQ70mBH3F",
        "outputId": "4ce22fe7-aae4-403b-e13e-fe0b26df8f38"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "target",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "text",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "sentiment",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "0fc66c97-d64f-4757-af06-5c087cabbc12",
              "rows": [
                [
                  "1599995",
                  "4",
                  "just woke up having no school is the best feeling ever",
                  "2"
                ],
                [
                  "1599996",
                  "4",
                  "thewdbcom very cool to hear old walt interviews httpblipfmbmta",
                  "2"
                ],
                [
                  "1599997",
                  "4",
                  "are you ready for your mojo makeover ask me for details",
                  "2"
                ],
                [
                  "1599998",
                  "4",
                  "happy th birthday to my boo of alll time tupac amaru shakur",
                  "2"
                ],
                [
                  "1599999",
                  "4",
                  "happy charitytuesday thenspcc sparkscharity speakinguphh",
                  "2"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>just woke up having no school is the best feel...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>thewdbcom very cool to hear old walt interview...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>4</td>\n",
              "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>4</td>\n",
              "      <td>happy th birthday to my boo of alll time tupac...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>4</td>\n",
              "      <td>happy charitytuesday thenspcc sparkscharity sp...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         target                                               text  sentiment\n",
              "1599995       4  just woke up having no school is the best feel...          2\n",
              "1599996       4  thewdbcom very cool to hear old walt interview...          2\n",
              "1599997       4  are you ready for your mojo makeover ask me fo...          2\n",
              "1599998       4  happy th birthday to my boo of alll time tupac...          2\n",
              "1599999       4  happy charitytuesday thenspcc sparkscharity sp...          2"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e66bd04b",
      "metadata": {
        "id": "e66bd04b"
      },
      "outputs": [],
      "source": [
        "max_features = 5000\n",
        "max_length = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(data[\"text\"])\n",
        "X = pad_sequences(tokenizer.texts_to_sequences(data[\"text\"]), maxlen=max_length)\n",
        "y = data['sentiment'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "52f9aefa",
      "metadata": {
        "id": "52f9aefa"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "1f04d96f",
      "metadata": {
        "id": "1f04d96f"
      },
      "outputs": [],
      "source": [
        "num_classes = 3  # Update this based on your use case\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_features, output_dim=16),\n",
        "    SimpleRNN(64, activation='tanh', return_sequences=True),  # Change return_sequences to True\n",
        "    SimpleRNN(128, activation='tanh', return_sequences=True),\n",
        "    SimpleRNN(64, activation='tanh', return_sequences=False),  # The last RNN layer does not return sequences\n",
        "    Dense(num_classes, activation='softmax')  # Use softmax for multi-class classification\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy', # Use categorical_crossentropy for multi-class classification\n",
        "    optimizer=Adam(learning_rate = 0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "1a8a8593",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a8a8593",
        "outputId": "6643a8ff-11e7-4162-d443-0c52f1231e6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1809s\u001b[0m 785ms/step - accuracy: 0.8469 - loss: 0.3464 - val_accuracy: 0.8042 - val_loss: 0.4441\n",
            "Epoch 2/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 275ms/step - accuracy: 0.8462 - loss: 0.3470 - val_accuracy: 0.8012 - val_loss: 0.4419\n",
            "Epoch 3/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 275ms/step - accuracy: 0.8482 - loss: 0.3445 - val_accuracy: 0.8038 - val_loss: 0.4434\n",
            "Epoch 4/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 273ms/step - accuracy: 0.8482 - loss: 0.3435 - val_accuracy: 0.7991 - val_loss: 0.4568\n",
            "Epoch 5/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1046s\u001b[0m 454ms/step - accuracy: 0.8472 - loss: 0.3458 - val_accuracy: 0.8037 - val_loss: 0.4454\n",
            "Epoch 6/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1340s\u001b[0m 582ms/step - accuracy: 0.8478 - loss: 0.3442 - val_accuracy: 0.8016 - val_loss: 0.4485\n",
            "Epoch 7/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2109s\u001b[0m 915ms/step - accuracy: 0.8497 - loss: 0.3417 - val_accuracy: 0.8005 - val_loss: 0.4521\n",
            "Epoch 8/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m647s\u001b[0m 281ms/step - accuracy: 0.8493 - loss: 0.3419 - val_accuracy: 0.8006 - val_loss: 0.4598\n",
            "Epoch 9/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 282ms/step - accuracy: 0.8499 - loss: 0.3420 - val_accuracy: 0.8025 - val_loss: 0.4449\n",
            "Epoch 10/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 283ms/step - accuracy: 0.8495 - loss: 0.3419 - val_accuracy: 0.7994 - val_loss: 0.4567\n",
            "Epoch 11/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 288ms/step - accuracy: 0.8491 - loss: 0.3419 - val_accuracy: 0.8003 - val_loss: 0.4539\n",
            "Epoch 12/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 288ms/step - accuracy: 0.8496 - loss: 0.3413 - val_accuracy: 0.8004 - val_loss: 0.4521\n",
            "Epoch 13/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m669s\u001b[0m 290ms/step - accuracy: 0.8507 - loss: 0.3391 - val_accuracy: 0.7999 - val_loss: 0.4536\n",
            "Epoch 14/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1134s\u001b[0m 492ms/step - accuracy: 0.8505 - loss: 0.3403 - val_accuracy: 0.8000 - val_loss: 0.4554\n",
            "Epoch 15/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2294s\u001b[0m 996ms/step - accuracy: 0.8497 - loss: 0.3411 - val_accuracy: 0.8009 - val_loss: 0.4533\n",
            "Epoch 16/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2179s\u001b[0m 946ms/step - accuracy: 0.8506 - loss: 0.3403 - val_accuracy: 0.7988 - val_loss: 0.4556\n",
            "Epoch 17/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2334s\u001b[0m 1s/step - accuracy: 0.8498 - loss: 0.3405 - val_accuracy: 0.8013 - val_loss: 0.4507\n",
            "Epoch 18/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1947s\u001b[0m 845ms/step - accuracy: 0.8516 - loss: 0.3383 - val_accuracy: 0.7989 - val_loss: 0.4752\n",
            "Epoch 19/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2010s\u001b[0m 873ms/step - accuracy: 0.8509 - loss: 0.3385 - val_accuracy: 0.8010 - val_loss: 0.4554\n",
            "Epoch 20/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21615s\u001b[0m 9s/step - accuracy: 0.8511 - loss: 0.3388 - val_accuracy: 0.7977 - val_loss: 0.4715\n",
            "Epoch 21/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1474s\u001b[0m 640ms/step - accuracy: 0.8502 - loss: 0.3406 - val_accuracy: 0.8001 - val_loss: 0.4631\n",
            "Epoch 22/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1807s\u001b[0m 763ms/step - accuracy: 0.8519 - loss: 0.3373 - val_accuracy: 0.7998 - val_loss: 0.4650\n",
            "Epoch 23/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m706s\u001b[0m 306ms/step - accuracy: 0.8510 - loss: 0.3392 - val_accuracy: 0.8003 - val_loss: 0.4568\n",
            "Epoch 24/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m718s\u001b[0m 312ms/step - accuracy: 0.8507 - loss: 0.3393 - val_accuracy: 0.7990 - val_loss: 0.4601\n",
            "Epoch 25/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m714s\u001b[0m 310ms/step - accuracy: 0.8516 - loss: 0.3370 - val_accuracy: 0.7991 - val_loss: 0.4638\n",
            "Epoch 26/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 314ms/step - accuracy: 0.8516 - loss: 0.3375 - val_accuracy: 0.7998 - val_loss: 0.4593\n",
            "Epoch 27/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 315ms/step - accuracy: 0.8516 - loss: 0.3375 - val_accuracy: 0.8003 - val_loss: 0.4595\n",
            "Epoch 28/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 320ms/step - accuracy: 0.8505 - loss: 0.3401 - val_accuracy: 0.7977 - val_loss: 0.4684\n",
            "Epoch 29/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m730s\u001b[0m 317ms/step - accuracy: 0.8521 - loss: 0.3365 - val_accuracy: 0.8007 - val_loss: 0.4669\n",
            "Epoch 30/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m733s\u001b[0m 318ms/step - accuracy: 0.8516 - loss: 0.3374 - val_accuracy: 0.7995 - val_loss: 0.4628\n",
            "Epoch 31/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 321ms/step - accuracy: 0.8511 - loss: 0.3387 - val_accuracy: 0.8000 - val_loss: 0.4569\n",
            "Epoch 32/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 324ms/step - accuracy: 0.8513 - loss: 0.3373 - val_accuracy: 0.7969 - val_loss: 0.4602\n",
            "Epoch 33/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m747s\u001b[0m 324ms/step - accuracy: 0.8516 - loss: 0.3375 - val_accuracy: 0.7991 - val_loss: 0.4609\n",
            "Epoch 34/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m755s\u001b[0m 328ms/step - accuracy: 0.8514 - loss: 0.3378 - val_accuracy: 0.7997 - val_loss: 0.4516\n",
            "Epoch 35/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m764s\u001b[0m 331ms/step - accuracy: 0.8490 - loss: 0.3426 - val_accuracy: 0.7991 - val_loss: 0.4607\n",
            "Epoch 36/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m766s\u001b[0m 333ms/step - accuracy: 0.8518 - loss: 0.3372 - val_accuracy: 0.7984 - val_loss: 0.4713\n",
            "Epoch 37/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m775s\u001b[0m 336ms/step - accuracy: 0.8513 - loss: 0.3386 - val_accuracy: 0.7978 - val_loss: 0.4693\n",
            "Epoch 38/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 337ms/step - accuracy: 0.8495 - loss: 0.3412 - val_accuracy: 0.7989 - val_loss: 0.4611\n",
            "Epoch 39/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m783s\u001b[0m 340ms/step - accuracy: 0.8519 - loss: 0.3371 - val_accuracy: 0.7965 - val_loss: 0.4552\n",
            "Epoch 40/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m785s\u001b[0m 341ms/step - accuracy: 0.8512 - loss: 0.3388 - val_accuracy: 0.7995 - val_loss: 0.4632\n",
            "Epoch 41/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m785s\u001b[0m 341ms/step - accuracy: 0.8515 - loss: 0.3380 - val_accuracy: 0.7982 - val_loss: 0.4623\n",
            "Epoch 42/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m789s\u001b[0m 342ms/step - accuracy: 0.8519 - loss: 0.3367 - val_accuracy: 0.7977 - val_loss: 0.4607\n",
            "Epoch 43/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m810s\u001b[0m 346ms/step - accuracy: 0.8512 - loss: 0.3389 - val_accuracy: 0.7996 - val_loss: 0.4612\n",
            "Epoch 44/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 348ms/step - accuracy: 0.8517 - loss: 0.3373 - val_accuracy: 0.7998 - val_loss: 0.4593\n",
            "Epoch 45/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m805s\u001b[0m 349ms/step - accuracy: 0.8512 - loss: 0.3387 - val_accuracy: 0.8002 - val_loss: 0.4705\n",
            "Epoch 46/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m811s\u001b[0m 352ms/step - accuracy: 0.8503 - loss: 0.3409 - val_accuracy: 0.7985 - val_loss: 0.4659\n",
            "Epoch 47/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m814s\u001b[0m 353ms/step - accuracy: 0.8513 - loss: 0.3386 - val_accuracy: 0.7977 - val_loss: 0.4703\n",
            "Epoch 48/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m840s\u001b[0m 364ms/step - accuracy: 0.8513 - loss: 0.3377 - val_accuracy: 0.7987 - val_loss: 0.4591\n",
            "Epoch 49/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m824s\u001b[0m 358ms/step - accuracy: 0.8514 - loss: 0.3391 - val_accuracy: 0.7972 - val_loss: 0.4621\n",
            "Epoch 50/50\n",
            "\u001b[1m2304/2304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m822s\u001b[0m 357ms/step - accuracy: 0.8511 - loss: 0.3397 - val_accuracy: 0.7990 - val_loss: 0.4580\n",
            "Test accuracy: 0.80\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=500,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {score[1]:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "6vTC0VjgIdau",
      "metadata": {
        "id": "6vTC0VjgIdau"
      },
      "outputs": [],
      "source": [
        "# Save the whole model (architecture + weights + optimizer state)\n",
        "model.save('models/model_SentRnn.keras')\n",
        "\n",
        "# To load it back:\n",
        "model = load_model('models/model_SentRnn.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "d408569e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d408569e",
        "outputId": "454bf2ce-48e2-4f49-a361-984b6676af47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: The food was great.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Sentiment: Positive (Probability: 0.97)\n"
          ]
        }
      ],
      "source": [
        "# Define class labels according to your training\n",
        "class_labels = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "def predict_sentiment(review_text):\n",
        "    text = clean_text(review_text)  # Clean the input text\n",
        "\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(seq, maxlen=max_length)\n",
        "\n",
        "    prediction = model.predict(padded)[0]  # Now returns an array of probabilities\n",
        "    predicted_class = prediction.argmax()  # Get the index of the highest probability\n",
        "    confidence = prediction[predicted_class]  # Get the confidence of the predicted class\n",
        "\n",
        "    return f\"{class_labels[predicted_class]} (Probability: {confidence:.2f})\"\n",
        "\n",
        "# Example usage\n",
        "sample_review = \"The food was great.\"\n",
        "print(f\"Review: {sample_review}\")\n",
        "print(f\"Sentiment: {predict_sentiment(sample_review)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f399b36",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
